## 4.1 Backus-Naur-Form

- Backus-Naur-Form (künstliche Sprache zur Beschreibung von Daten und Abläufen)
- Nichtterminalsymbole sind von spitzen Klammern umschlossen
- Ein senkrechter Strich drückt aus, dass genau eine von mehreren Möglichkeiten auszuwählen ist

```
<Ziffer>::= '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '0'
<Buchstabe>::= 'a' | ... | 'z' | 'A' | ... | 'Z'
<Variable>::= (Buchstabe | '_' ) (Buchstabe | '_' | Ziffer)*
```

Eine Variable ist ein Buchstabe oder Unterstrich, gefolgt von null-, ein- oder mehrfachem Auftreten von Buchstaben, Unterstrichen und Ziffern

### 4.1.1 Erweiterte BNF

- Terminalsymbole sind von Anführungszeichen umschlossen
- Zusätzliche Notationselemente für Wiederholung und Optionalität
- runde Klammern dienen lediglich der besseren Lesbarkeit

- Symbol? – null- oder einmaliges Vorkommen von Symbol
- Symbol* - null- ein- oder mehrmaliges Vorkommen von Symbol
- Symbol+ - ein- oder mehrmaliges Vorkommen von Symbol

![[Pasted image 20251124140146.png]]

### 4.1.2 Alternative Darstellungen

- {} steht für 0 bis n-fache Wiederholung
- `[]` steht für Optionalität (0 oder einfaches Vorkommen)
- | trennt Varianten voneinander
- __fett__: Terminalsymbole
- _kursiv_: Nicht-Terminalsymbole

### 4.1.3 Syntax-Diagramm

![[Pasted image 20251124140047.png]]

### 4.1.4 Operatoren

![[Pasted image 20251124141333.png]]

### 4.1.5 Kontrollstrukturen

![[Pasted image 20251124141311.png]]

## 4.2 Formale Sprachen

Formale Sprachen sind Systeme, die Regeln für den Aufbau von Zeichenketten (Sätzen) festlegen. Im Gegensatz zu natürlichen Sprachen (wie Deutsch) oder Programmiersprachen haben sie keine vordefinierte Bedeutung (Semantik). Es geht nur darum, ob eine Zeichenkette den festgelegten Regeln entspricht (Syntax).

Anwendungsgebiete:
- Linguistik (Sprachwissenschaft), um die Struktur von Sprachen zu verstehen
- Compiler- und Interpreterbau, um Programmcode zu analysieren
- Parser, um Datenstrukturen zu verarbeiten
- Künstliche Intelligenz, Bsp.: für die Verarbeitung natürlicher Sprache

**Syntax**: beschreibt die Regeln, wie die Elemente einer Sprache korrekt zusammengesetzt werden dürfen.

## 4.3 Ableitungsbaum

Ein Ableitungsbaum (auch Syntaxbaum genannt) hilft uns, die Struktur eines Satzes oder einer Zeichenkette zu visualisieren und zu verstehen. Er zeigt, wie ein Satz aus den Regeln einer formalen Sprache abgeleitet wurde.

Man kann einen Ableitungsbaum auf zwei Arten verwenden:
-  einen Satz erzeugen (Synthese)
-  einen Satz auf seine Korrektheit prüfen (Analyse)

Bsp.: In der deutschen Sprache gibt es die Regel "Subjekt – Prädikat – Objekt" (SPO).
Der Satz: „Der kleine Hund jagt die große Katze“ kann mit einem Ableitungsbaum analysiert werden.

![[Pasted image 20251124142806.png]]

## 4.4 Nicht-Terminale

Nicht-Terminale sind wie Platzhalter für Bausteine. Sie sind abstrakte Kategorien, die beschreiben, was an einer bestimmten Stelle im Satz oder Ausdruck stehen *kann*, aber sie sind selbst keine konkreten Wörter oder Zeichen im fertigen Ergebnis.
-  Stell dir vor, du baust ein Lego-Haus. `Wand`, `Dach`, `Fenster` sind Nicht-Terminale – sie beschreiben die Teile, aus denen das Haus besteht, aber sie sind keine einzelnen Legosteine selbst.
-  Im Bsp. des Ableitungsbaums sind `Subjekt`, `Prädikat` und `Objekt` Nicht-Terminale.
-  Im fertigen Satz siehst du die Nicht-Terminale nicht mehr, nur noch die konkreten Wörter, die sie ersetzt haben.
-  Sie helfen, die Regeln einer Sprache klar und strukturiert festzulegen.

## 4.5 Terminale

- Grundbausteine der Sprache. Sie sind vom „Design“ der Sprache vorgegeben.
  Es sind die erlaubten Zeichen, Konstanten, Schlüsselwörter usw. ('if' , 'for', 'while', '1', '2' ... , 'a', ... ,'z', 'A', ..., 'Z', '_')
- das Nicht-Terminal, das die „Wurzel“ des Syntaxbaumes bildet, heißt Axiom, Satzsymbol, Spitzensymbol oder Startsymbol
- die Satzerzeugung beginnt mit dem Startsymbol und endet, wenn alle Nicht-Terminale durch Terminalsymbole ersetzt sind.

Bssp.: ::= Ausdruck '?' Ausdruck ':' Ausdruck

## 4.6 Ableitung, Herleitung

Um aus einer begrenzten Anzahl von Regeln unendlich viele Sätze (Ausdrücke) einer Sprache erzeugen zu können, verwenden wir Ableitungen.

Jede Regel hat die Form: `linke Seite → rechte Seite`.
-   Die **linke Seite** ist das, was ersetzt werden soll (meist ein Nicht-Terminal).
-   Die **rechte Seite** ist das, wodurch es ersetzt wird (eine Folge von Terminal- und/oder Nicht-Terminalsymbolen).

**Kontextfreie Grammatiken**

- Wenn die linke Seite einer Regel immer nur aus einer *einzelnen Variablen* (einem Nicht-Terminal) besteht, spricht man von einer **kontextfreien Grammatik**. Das bedeutet, das Nicht-Terminal kann ersetzt werden, egal in welchem "Kontext" es steht.
- **Gegenbeispiel:** `'*'<Variable>::= ...` wäre keine kontextfreie Regel und auch nicht in der Backus-Naur-Form (BNF) zulässig, weil die linke Seite nicht nur aus einer einzelnen Variablen besteht.
- Beachte: Das Symbol `*` (Stern) kann in verschiedenen Zusammenhängen unterschiedliche Bedeutungen haben (Bsp.: als Terminalsymbol oder als Operator für Wiederholung).

**Ableitungen in kontextfreien Grammatiken**

>Eine Ableitung ist der Schritt-für-Schritt-Prozess, bei dem wir die Regeln anwenden, um aus einem Startsymbol einen fertigen Satz zu bilden. Es gibt verschiedene Arten, diese Schritte auszuführen:

- **„normale“ Ableitung** $\Rightarrow$ Es wird ein beliebiges Nicht-Terminal in der aktuellen Satzform durch seine rechte Seite einer Regel ersetzt.
- **Links-Ableitung** $\Rightarrow_L$ Es wird immer das Nicht-Terminal ersetzt, das in der Satzform am weitesten links steht.
- **Rechts-Ableitung** $\Rightarrow_R$ Es wird immer das Nicht-Terminal ersetzt, das in der Satzform am weitesten rechts steht.
- **Parallel-Ableitung** $\Rightarrow_{|\space|}$ Alle in der Satzform vorkommenden Nicht-Terminale werden gleichzeitig in einem Schritt ersetzt.

>Wichtig ist: Alle diese Ableitungsvarianten führen am Ende zur **selben Sprache**, also zum selben Satz an gültigen Zeichenketten. Sie sind nur unterschiedliche Wege, um dorthin zu gelangen.

## 4.7 Symbole und Wörter

Ein __Alphabet__ ist eine endliche nichtleere Menge, von __Zeichen__ oder __Symbolen__.

Bsp.:
$\sum _1$ = {0, 1}
$\sum _2$ = {a, ... , z}
$\sum _3$ = {0, 1, a, b, c}
$\sum _4$ = {continue, break, return} (Ist auch als Menge von nicht mehr teilbaren Symbolen anzusehen.)

Ein __Wort__ über einem Alphabet ist eine endliche Folge von Symbolen über diesem Alphabet.

Bsp.:
01001 ist ein Wort über $\sum _1$
abbeb ist ein Wort über $\sum _2$

## 4.8 Wörter

Ist $w$ ein Wort über $\sum$, dann ist die __Länge von $w$__ in Zeichen __|$w$|__, die Anzahl der Symbole, die $w$ enthält.

Bsp.: $\sum$ = { 0, 1 }    $w$ = 0101    | $w$ | = 4

Hat ein Wort $w$ über $\sum$ die Länge $n$, dann schreiben wir $w = a_1, a_2, \dots, a_n$ wobei jedes $a_1 \in \sum$.

Das Wort mit der Länge 0 heißt __Leerwort__, geschrieben $\epsilon$ (| $\epsilon$ | = 0).

## 4.9 Konkatenation

- Haben wir ein Wort $x$ der Länge $n$ und ein Wort $y$ der Länge $m$, dann ist die **Verkettung (Konkatenation)** von $x$ und $y$ das Wort, das man durch Hintereinanderschreiben von $x$ und $y$ erhält: $x \cdot y = xy$. Die Länge des verketteten Wortes ist $|xy| = n+m$.


__Potenzbildung__

Um ein Wort mit sich selbst mehrere Male zu verketten, benutzen wir folgende Notation:

- Die $k$-fache Verkettung eines Wortes $w$ mit sich selbst wird als $w^k$ geschrieben: $w^k = \underbrace{w \cdot w \cdot \space \dots \space \cdot w}_{k}$
- Das Wort mit der Länge 0, das **Leerwort** $\epsilon$, ist definiert als $w^0$: $w^0 = \epsilon$
- Eine rekursive Definition für $w^n$ ist: $w^n = w \cdot w^{n-1}$

Weitere wichtige Mengen in Bezug auf Alphabete und Wörter sind:

- $\Sigma^*$ (Kleene-Stern-Abschluss):
  Dies ist die Menge aller möglichen Wörter, die über einem Alphabet $\Sigma$ gebildet werden können, **inklusive des Leerworts** $\epsilon$. Es umfasst Wörter jeder beliebigen Länge (von 0 bis unendlich).
  $\Sigma^* = \bigcup_{0 \le i} \Sigma^i$
- $\Sigma^+$ (positiver Abschluss):
  Diese Menge enthält alle **nicht-leeren** Wörter, die über dem Alphabet $\Sigma$ gebildet werden können. Es ist somit $\Sigma^*$ abzüglich des Leerworts $\epsilon$.
  $\Sigma^+ = \bigcup_{1 \le i} \Sigma^i$
- $\Sigma^{\le n}$:
  Dies ist die Menge aller Wörter über dem Alphabet $\Sigma$, deren Länge **höchstens $n$ Symbole** beträgt.
  $\Sigma^{\le n} = \bigcup_{0 \le i \le n} \Sigma^i$

## 4.10 Formale Sprachen

>Eine formale Sprache ist eine beliebige Teilmenge $L$ von $\Sigma^*$ ($L \subseteq \Sigma^*$).

- Die Elemente von $L$ heißen Wörter (Sätze)
- Die zulässigen Sprachen $\varnothing$ (leere Sprache) und $\Sigma^*$ (Allsprache) sind wenig sinnvoll. Die Allsprache hat keinerlei Regeln
- Die Länge der Ableitung (der Schritt-für-Schritt-Prozess, um einen Satz aus den Regeln einer formalen Sprache zu erzeugen) spielt keine Rolle
- Es kann mehrere Ableitungen für ein Wort (Satz) geben (unerwünscht). Es gibt keinen Automatismus beim „Aufspüren“ von Mehrdeutigkeiten.


__Es gilt:__

Die Menge aller Wörter die mit dem Alphabet gebildet werden kann $\Sigma^*$, ist die Vereinigung aller Mengen $\Sigma^n$ für alle $n \in \mathbb{N}$. Üblicherweise wird hier $\mathbb{N}$ als $\mathbb{N}_0 = \{ 0, 1, 2, \dots \}$ verstanden, um auch das Leerwort $\epsilon$ einzuschließen.
$$\Sigma^* = \bigcup_{n \in \mathbb{N}} \Sigma^n \text{ wobei } \Sigma^n = \{ x_1, x_2, \dots, x_n \mid x_i \in A \text{ und } 0 \le i \le 1 \,\}$$
Die Menge aller Wörter die mit dem Alphabet gebildet werden kann und das Leerwort nicht enthält $\Sigma^*$, ist die Vereinigung aller Mengen für alle $n \in \mathbb{N}_1$.

$$\Sigma^+ = \bigcup_{n \le N_1} \Sigma^n$$

__Weiterhin:__

Sei  und $w = xuy$ für beliebige Wörter $x, u, y \in \Sigma^*$, so ist $x$ __Präfix__, $u$ __Teilwort__ und $y$ Suffix von $w$.

Sei $w = a_1a_2...a_{n-1}a_n$ ein Wort aus $\Sigma^*$, so ist das __Spiegelbild__ $w^r = a_n a_{n-1} ... a_2a_1$. Hierbei werden die Symbole des Wortes in umgekehrter Reihenfolge angeordnet.

Ein Wort $w \in \Sigma^*$ ist ein **Palindrom**, wenn es seinem Spiegelbild $w^r$ gleicht, also $w = w^r$.

## 4.11 Operationen auf formalen Sprachen

$A$ und $B$ seien Sprachen.
$$A = \{ \text{ good, bad } \} \text{ und } B = \{ \text{ girl, boy } \}$$

__Vereinigung:__

$$A \cup B = \{ x \mid x \in A \text{ oder } x \in B \} = \{ \text{ good, bad, boy, girl } \}$$

__Konkatenation:__

$$A \cdot B = \{ xy \mid x \in A \text{ und } y \in B \} = \{ \text{ goodgirl, goodboy, badgirl, badboy } \}$$

Die Reihenfolge ist hierbei relevant, denn:

$$B \cdot A = \{ yx \mid y \in B \text{ und } x \in A \} = \{ \text{ girlgood, girlbad, boygood, boybad } \}$$

__Kleene-Stern:__

$$A* = \{ x_1 x_2 \dots x_k \mid x_i \in A \text{ und } 0 \le i \le k \} = \{ \epsilon, \text{ good, bad, goodgood, goodbad, badgood, badbad, goodgoodgood, goodgoodbad, goodbadgood, goodbadbad } \}$$


__Rechenregeln__

Vereinigung, Schnitt, Komplement und Differenz von Sprachen: wie bei Mengen.

- $A \cup B = B \cup A$
- $A \cup (B \cup C) = (A \cup B) \cup C$
- $A \cdot (B \cdot C) = (A \cdot B) \cdot C$
- $A \cdot (B \cup C) = A \cdot B \cup A \cdot C$
- $(B \cup C) \cdot A = B \cdot A \cup C \cdot A$

$\{\varepsilon\} \cdot A = A$
Die Verkettung der Sprache, die nur das Leerwort $\varepsilon$ enthält, mit einer beliebigen Sprache $A$ ergibt wieder die Sprache $A$. Das Leerwort verändert bei der Verkettung nichts

$A \cdot \{\varepsilon\} = A$
Ähnlich wie oben: Die Verkettung einer Sprache $A$ mit der Sprache, die nur das Leerwort $\varepsilon$ enthält, von rechts, ergibt ebenfalls wieder die Sprache $A$

$(A \cup \{ \epsilon \})^* = A^*$
Der Kleene-Stern einer Sprache $A$, die um das Leerwort $\varepsilon$ erweitert wurde, ist identisch mit dem Kleene-Stern von $A$. Das liegt daran, dass $A^*$ per Definition bereits das Leerwort $\varepsilon$ enthält

$(A^*)^* = A^*$
Das Anwenden des Kleene-Stern-Operators zweimal auf eine Sprache hat keinen zusätzlichen Effekt. Die Menge $A^*$ enthält bereits alle möglichen Verkettungen von Wörtern aus $A$, einschließlich des Leerwortes

$A \cdot A^* = A^+$
Die Verkettung der Sprache $A$ mit ihrem Kleene-Stern $A^*$ ergibt den positiven Abschluss $A^+$. Da $A^*$ das Leerwort $\varepsilon$ enthält, wird $A \cdot A^*$ zu $A \cdot (\varepsilon \cup A \cup A \cdot A \cup \dots) = A \cup A \cdot A \cup A \cdot A \cdot A \cup \dots$, was genau der Definition von $A^+$ entspricht (alle nicht-leeren Wörter)

$A^* \cdot A = A^+$
Diese Regel ist ähnlich der vorherigen, nur dass die Verkettungsreihenfolge vertauscht ist. Das Ergebnis bleibt dasselbe, der positive Abschluss $A^+$. $A^* \cdot A = (\varepsilon \cup A \cup A \cdot A \cup \dots) \cdot A = A \cup A \cdot A \cup A \cdot A \cdot A \cup \dots$

$A^+ \cup \{\varepsilon\} = A^*$
Die Vereinigung des positiven Abschlusses $A^+$ (alle nicht-leeren Wörter) mit der Sprache, die nur das Leerwort $\varepsilon$ enthält, ergibt den Kleene-Stern $A^*$. Dies liegt daran, dass $A^+$ alle Wörter außer $\varepsilon$ enthält und durch Hinzufügen von $\varepsilon$ die vollständige Menge $A^*$ entsteht.

## 4.12 Induktive Definition

Eine induktive Definition ist eine Methode, um eine Menge ganz genau zu beschreiben, indem man festlegt, wie sie *beginnt* und wie man *neue Elemente* daraus *erzeugt*.
* man startet mit einer Grundmenge $B$ und hat Regeln (Operatoren)
* die Anwendung dieser Regeln auf Elemente aus $B$ sollte wieder Elemente aus $B$ ergeben

>Eine Menge $A \subseteq B$ ist *abgeschlossen* unter einem Operator $f: B^n \rightarrow B$, wenn gilt:
>Sind $x_1, \dots, x_n \in A$, dann ist auch $f(x_1, \dots, x_n) \in A$.

Das bedeutet: Wenn man eine Regel auf Elemente anwendet, die bereits in $A$ sind, dann ist das Ergebnis ebenfalls in $A$.

Das **allgemeine Schema** einer induktiven Definition sieht so aus:
$A$ ist die kleinste Menge, für die gilt:
- (1) Es gibt Start-Elemente ($A_0$), die sicher zu $A$ gehören
- (2) Wenn $x_1, \dots, x_n$ schon Elemente von $A$ sind, dann ist auch das Ergebnis der Anwendung einer Regel (Bsp.: ein Operator $f(x_1, \dots, x_n)$) in $A$.

Die drei Komponenten einer induktiven Definition sind:
* **Grundmenge (Basiselemente):** Das sind die ersten Elemente, mit denen die Menge anfängt.
* **Abschlusseigenschaft (Regeln zur Bildung):** Hier beschreibt man, wie man aus Elementen, die schon in der Menge sind, neue erzeugen kann.
* **Minimalitätsbedingung:** Es gehören nur die Elemente zur Menge, die durch die Start-Elemente und die Erzeugungsregeln entstanden sind.


**Bsp.: Definition der Palindrome**

Ein Palindrom ist ein Wort, das vorwärts und rückwärts gelesen gleich ist (Bsp.: "anna", "otto").

Die Menge der Palindrome ist die kleinste Menge, für die gilt:
* (1) Das Leerwort $\epsilon$ ist ein Palindrom (der Startpunkt)
* (2) Für jedes Symbol $a$ ist $a$ ein Palindrom (einzelne Buchstaben sind auch Palindrome)
* (3) Ist $a$ ein Symbol und $x$ ein Palindrom, dann ist auch $axa$ ein Palindrom (man kann ein Palindrom $x$ mit dem gleichen Symbol $a$ vorne und hinten erweitern, um ein neues Palindrom zu bilden)


**Bsp.: Definition der wohlgeformten Klammerausdrücke (WKA)**

Ein WKA sind Klammerausdrücke, die korrekt geschlossen sind, Bsp.: `[]` oder `[[]]` aber nicht `][`.

Die Menge der wohlgeformten Klammerausdrücke (WKA) über dem Alphabet $\{ [, ] \}$ ist die kleinste Menge, für die gilt:
* (1) Das Leerwort $\epsilon$ ist ein WKA (der Startpunkt, ein leerer Ausdruck ist korrekt)
* (2) Ist $w$ ein WKA, dann ist auch $[w]$ ein WKA (man kann einen WKA in Klammern setzen, um einen neuen zu bilden)
* (3) Sind $w$ und $v$ WKA, dann ist auch $wv$ ein WKA (man kann zwei WKA aneinanderhängen, um einen neuen zu bilden)

## 4.13 Grammatiken

>Das fundamentale Modell zur Beschreibung von formalen Sprachen durch Erzeugungsmechanismen sind Grammatiken.

Eine Grammatik wird als Quadrupel $(N, T, P, S)$ definiert:

* **N (Nonterminale):** Dies ist die Menge der Nicht-Terminalsymbole, auch Variablen genannt. Sie sind Platzhalter für Bausteine, die im Laufe der Ableitung durch andere Symbole ersetzt werden müssen (Bsp.: `<Variable>`, `<Ausdruck>`).
* **T (Terminale):** Dies ist die Menge der Terminalsymbole. Das sind die grundlegenden, nicht weiter zerlegbaren Zeichen, die in der fertigen Sprache erscheinen (Bsp.: 'a', '1', 'if', ';').
* **P (Produktionen):** Dies ist eine endliche Menge von Ersetzungsregeln, auch Produktionen genannt. Sie geben an, wie Symbole oder Symbolfolgen durch andere Symbole oder Symbolfolgen ersetzt werden dürfen. Eine Produktion hat die Form $\alpha \rightarrow \beta$.
* **S (Startsymbol):** Dies ist ein spezielles Nicht-Terminalsymbol aus $N$, das den Beginn jeder Ableitung (also der Erzeugung eines Satzes) markiert.

Wichtig ist, dass die Menge der Nonterminale $N$ und die Menge der Terminale $T$ disjunkt sind, d.h. sie haben keine gemeinsamen Symbole:  
$N \cap T = \{\}$

Die Menge aller Symbole, sowohl Terminale als auch Nonterminale, wird als Vokabular $V$ bezeichnet:  
$V := N \cup T$

Die Produktionen $P$ sind eine Teilmenge von $V^{+} \times V^{*}$. Das bedeutet:

* Die **linke Seite** einer Produktion ($\alpha$ in $\alpha \rightarrow \beta$) muss aus mindestens einem Symbol des Vokabulars $V$ bestehen ($V^{+}$ schließt das Leerwort aus)
* Die **rechte Seite** einer Produktion ($\beta$ in $\alpha \rightarrow \beta$) kann aus beliebigen Symbolfolgen des Vokabulars $V$ bestehen, einschließlich des Leerworts ($V^{*}$ schließt das Leerwort ein)

Statt des Paares $(\alpha, \beta)$ wird üblicherweise die Notation $\alpha \rightarrow \beta$ verwendet.

___

__Beispiel 1__

Eine Grammatik $G_1$ ist wie folgt definiert:
$$G_1 = ( \{ S \}, \{a\}, \{S \rightarrow \varepsilon, S \rightarrow aS\}, S)$$
$$L(G_1) = \{ \epsilon \} \cup \{ a^n \mid n \ge 1 \} = \{a\}^*$$
**Worterzeugung:**
Wir starten immer mit $S$ und wenden die Regeln an, bis alle $S$ verschwunden sind.

* Leerwort $\epsilon$ erzeugen: $S \Rightarrow \epsilon$ (Regel $S \rightarrow \epsilon$)
* Wort $a$ erzeugen: $S \Rightarrow aS \Rightarrow a\epsilon = a$ (Regel $S \rightarrow aS$, dann $S \rightarrow \epsilon$)
* Wort $aa$ erzeugen: $S \Rightarrow aS \Rightarrow aaS \Rightarrow aa\epsilon = aa$ (Regel $S \rightarrow aS$ zweimal, dann $S \rightarrow \epsilon$)

Die einzelnen Schritte zusammengefasst:
$$S \Rightarrow \epsilon$$
$$S \Rightarrow^n a^nS \Rightarrow^1 a^n\epsilon \text{ für } n \in N_1$$
- Hier bedeutet $S \Rightarrow^n a^nS$, dass wir Regel 2 ($S \rightarrow aS$) $n$-mal hintereinander angewendet haben.
- Dann bedeutet $\Rightarrow^1 a^n\epsilon$, dass wir Regel 1 ($S \rightarrow \epsilon$) einmal angewendet haben, um das letzte $S$ zu entfernen

___

__Beispiel 2__

Eine Grammatik $G_2$ ist wie folgt definiert:

$$G_2 = ( \{S\}, \{a, b\}, \{ S \rightarrow aSb, S \rightarrow \epsilon\}, S)$$

$$L(G_2) = \{ a^n b^n \mid n \in \mathbf{N} \}$$

Alle in $G_2$ möglichen Ableitungen sind von der Gestalt:
$$S \Rightarrow^n a^nSb^n \Rightarrow a^nb^n \text{ für alle } n \in \mathbf{N}_1$$

Menge aller Satzformen nach genau $n$ Schritten:
$$SF(G_2, n) = \{ a^nSb^n, a^{n-1}b^{n-1} \} \text{ für alle } n \in \mathbb{N}_1 \text{ mit  } w^0 = \epsilon$$
__Schritt 1:__
Regel $S \rightarrow aSb$ genau $n$-mal hintereinander anwenden, aber das letzte Nicht-Terminal $S$ noch nicht durch $\epsilon$ ersetzen.

$$a^nSb^n$$
Beispiele:
- Für $n=1$ ist dies $aSb$ (nach einem Schritt $S \Rightarrow aSb$).
- Für $n=2$ ist dies $aaSbb$ (nach zwei Schritten $S \Rightarrow aSb \Rightarrow aaSbb$).

__Schritt 2:__
Regel $S \rightarrow aSb$ $(n-1)$-mal anwenden und der *n-te* und letzte Schritt die Anwendung von $S \rightarrow \epsilon$.
$$a^{n-1}b^{n-1}$$
Diese Form ist ein *fertiges Wort* (enthält keine Nicht-Terminale mehr).
Sie entsteht, wenn die  $w^0 = \epsilon$: Dies ist eine Notation, die besagt, dass $a^0b^0$ als das Leerwort $\epsilon$ interpretiert wird, was für den Fall $n=1$ (also $a^{1-1}b^{1-1}$) wichtig ist.

Induktionsbasis:       $SF(G_2,1) = \{ a^1Sb^1, \epsilon \}$
Induktionshypothese:  $SF(G_2,n) = \{ a^nSb^n, a^{n-1}b^{n-1} \}$
Induktionsbehauptung: $SF(G_2,n+1) = \{ a^{n+1}Sb^{n+1}, a^nb^n \}$

__Beweis__:
Das Wort $a^{n-1}b^{n-1}$ ist terminal und daher nicht mehr weiter ableitbar. Aus $a^nSb^n$ ist ableitbar:
mittels $S \rightarrow aSb : a^{n+1}Sb^{n+1}$
mittels $S \rightarrow \epsilon : a^nb^n$

___

__Beispiel 3__

Eine Grammatik $G_3$ ist wie folgt definiert:

$$G_3 = ( \{S, A, C\}, \{a, b, c\}, P_3, S)$$

$$P_3 = \{ S \rightarrow abc, S \rightarrow aAbc, A \rightarrow aAbC, A \rightarrow abC, Cb \rightarrow bC, Cc \rightarrow cc \}$$

$$L(G_3) = \{a^nb^nc^n \mid n \in \mathbb{N}_1 \}$$

Alle in $G_3$ möglichen Ableitungen sind von der Gestalt:

**Fall 1: Für $n=1$**

$$S \Rightarrow abc$$

**Fall 2: Für $n \ge 2$**

$$S \Rightarrow aAbc \Rightarrow^{n-2} a^{n-1} A(bC)^{n-2}bc \Rightarrow a^n A(bC)^{n-1}bc\Rightarrow^* a^nb^nc^n$$

**Erläuterung der Ableitung für $n \ge 2$:**

__Schritt 1:__
Es wird die Regel  $S\to aAbc$  verwendet.
Diese erzeugt:
- ein $a$ vorne,
- ein $A$ für die Rekursion,
- ein $bc$ hinten.

$$aAbc$$

__Schritt 2:__
Wir wenden $(n-2)$-mal  $A\to aAbC$ an.
Jede Anwendung erzeugt:
- vorn ein zusätzliches $a$,
- hinter dem $A$ ein weiteres $bC$,
- das $A$ bleibt erhalten.

Nach $(n-2)$ Anwendungen:

$$
a^{\,n-1} A (bC)^{\,n-2} bc
$$
Beispiele:
- $n=2$: 0 Anwendungen → $aAbc$
- $n=3$: 1 Anwendung → $aaA(bC)bc$
- $n=4$: 2 Anwendungen → $aaaA(bC)(bC)bc$

__Schritt 3:__
Eine weitere Anwendung von  $A\to aAbC$ führt zu:

$$
a^{n} A (bC)^{\,n-1} bc
$$
Wir haben jetzt:
- $n$ viele $a$
- $(n-1)$ Paare $bC$
- ein letztes $A$ für die Terminierung

__Schritt 4:__
Wir nutzen $A\to abC$
Dadurch entsteht ein **letztes** $bC$:
→ Jetzt existieren insgesamt $n$ Paare $(bC)$.

$$a^n \; (bC)^n \; c$$

Nach der Regel: $Cb \to bC$, wird $C$ nach rechts verschoben.
Jedes $C$ wandert durch alle $b$ hindurch nach rechts, bis alle $C$ gesammelt am rechten Ende stehen.

$$a^n \; b^n \; C^n \; c$$

$C$ in $c$ umwandeln nach Regel $Cc \to cc$

Jedes $C$ wird zu **zwei** $c$:
- eines ersetzt das ursprüngliche $c$,
- eines kommt neu hinzu.

Damit entstehen $n$ Stück $c$.

$$
a^n b^n c^n
$$

Die Grammatik erzeugt also exakt alle Wörter der Form $a^n b^n c^n$.

___

__Beispiel 4__

Eine Grammatik $G_4$ ist wie folgt definiert:

$$G_4 = ( \{S, A, B, M, X\}, \{a, b\}, P_4, S)$$

$$P_4 = \{ S \rightarrow XAbAMBaBX, bA \rightarrow Ab, XA \rightarrow aX, X \rightarrow \varepsilon, M \rightarrow AMB \mid bAMBa \mid \varepsilon, Ba \rightarrow aB, BX \rightarrow Xb \}$$

$$L(G_4) = \{ a^n b^m a^m b^n \in \{a, b\}^* \mid n > m > 0, n, m \in \mathbb{N}_1 \}$$

>Diese Grammatik ist eine Typ-0-Grammatik, da Regeln wie $X \rightarrow \varepsilon$ und $M \rightarrow \varepsilon$ die Länge der Satzform reduzieren können, und Regeln wie $XA \rightarrow aX$ oder $bA \rightarrow Ab$ auf der linken Seite mehr als ein Symbol haben oder eine Mischung aus Terminal- und Nicht-Terminalsymbolen darstellen. Die Sprachdefinition $n > m > 0$ impliziert, dass das Leerwort $\epsilon$ nicht Teil der Sprache ist. Daher sind die $\varepsilon$-Produktionen nur zum Entfernen der Nicht-Terminale am Ende des Ableitungsprozesses relevant, nachdem sie zur Generierung der Terminale beigetragen haben.

**Erläuterung der Ableitung:**

__Schritt 1:__
Wir beginnen mit dem Startsymbol $S$ und wenden die Regel $S \rightarrow XAbAMBaBX$ an.

$$S \Rightarrow XAbAMBaBX$$

__Schritt 2:__
Die Nicht-Terminale $X$ am Anfang und Ende des Ausdrucks sind für die Erzeugung der äußeren $a^n$- und $b^n$-Teile zuständig:
- **Für $a^n$ (links):** Die Regel $XA \rightarrow aX$ wird $n$-mal angewendet, um $n$ 'a'-Symbole zu generieren und $X$ nach rechts zu verschieben. Nach der Generierung aller 'a's wird das verbleibende $X$ mittels $X \rightarrow \varepsilon$ entfernt.
- **Für $b^n$ (rechts):** Die Regel $BX \rightarrow Xb$ wird $n$-mal angewendet, um $n$ 'b'-Symbole zu generieren und $X$ nach links zu verschieben. Anschließend wird $X$ durch $X \rightarrow \varepsilon$ entfernt.

$$a^n bAMBa b^n$$

__Schritt 3:__
Die Produktionen $M \rightarrow AMB$ und $M \rightarrow bAMBa$ können rekursiv angewendet werden, um die gewünschte Anzahl an $a$ und $b$ im Mittelteil zu erzeugen. Für $m>0$ wird $M \rightarrow \varepsilon$ erst nach der Erzeugung der Terminale genutzt.

Nach $(m-1)$ Anwendungen von $M \rightarrow AMB$ und einer Anwendung von $M \rightarrow bAMBa$ sowie anschließendem $M \rightarrow \varepsilon$ erhalten wir:

$$a^n bA^m bA^m a b^n$$

__Schritt 4:__
Nun müssen die Nicht-Terminale $A$ in der richtigen Reihenfolge entfernt werden, indem sie durch die Terminale "hindurchwandern". Die Regel $bA \rightarrow Ab$ verschiebt jedes $A$ nach rechts über die $b$'s hinweg:

- Die $m$ $A$'s auf der linken Seite wandern nach rechts über die $m$ $b$'s.
- Die $m$ $A$'s auf der rechten Seite wandern ebenfalls nach rechts.

Nach Anwendung von $bA \rightarrow Ab$ erhalten wir:

$$a^n A^m b^m a A^m b^n$$

__Schritt 5:__
Die verbliebenen $A$'s auf beiden Seiten werden nun durch die $B$'s "absorbiert" bzw. die $B$'s wandern nach links über die $a$'s. Die Regel $Ba \rightarrow aB$ verschiebt die $B$'s nach links:

Nach mehrfacher Anwendung von $Ba \rightarrow aB$ erhalten wir:

$$a^n A^m b^m B^m a^m b^n$$

__Schritt 6:__
Die verbleibenden $A$'s und $B$'s werden durch wiederholte Anwendung der Regeln entfernt. Da alle Nicht-Terminale ihre Aufgabe erfüllt haben (die Struktur ist korrekt aufgebaut), werden sie systematisch eliminiert. Dies geschieht implizit durch die bereits angewendeten Verschiebungsregeln.

Das Endergebnis ist:

$$a^n b^m a^m b^n \text{ mit } n > m > 0$$

## 4.14 Reguläre Mengen

Ein regulärer Ausdruck $\alpha$ definiert eine reguläre Sprache $L_{reg}(\alpha)$. Reguläre Ausdrücke sind wie eine Bauanleitung für eine Sammlung von Wörter. sind induktiv definiert:

* Die leere Menge $\varnothing$ ist ein regulärer Ausdruck. Sie beschreibt die leere Sprache: $L_{reg}(\varnothing) = \varnothing$
* Das Leerwort $\varepsilon$ ist ein regulärer Ausdruck. Es beschreibt die Sprache, die nur das Leerwort enthält: $L_{reg}(\varepsilon) = \{\varepsilon\}$
* Jedes einzelne Zeichen $a \in \Sigma$ ist ein regulärer Ausdruck. Es beschreibt eine Sprache, die nur dieses Zeichen als Wort enthält: $L_{reg}(a) = \{a\}$.
*  Wenn $\alpha$ und $\beta$ reguläre Ausdrücke sind, dann sind auch die folgenden Kombinationen reguläre Ausdrücke:
  - **Konkatenation** ($\alpha \text{ . } \beta$): Die Sprache $L_{reg}(\alpha\beta)$ enthält alle Wörter, die entstehen, wenn man ein Wort aus $L_{reg}(\alpha)$ mit einem Wort aus $L_{reg}(\beta)$ verbindet.
    $L_{reg}(\alpha\beta) = L_{reg}(\alpha) \circ L_{reg}(\beta)$
  - **Vereinigung** ($\alpha + \beta$): Die Sprache $L_{reg}(\alpha | \beta)$ enthält alle Wörter, die entweder in $L_{reg}(\alpha)$ oder in $L_{reg}(\beta)$ vorkommen.
    $L_{reg}(\alpha | \beta) = L_{reg}(\alpha) \cup L_{reg}(\beta)$.
  - **Kleene-Stern** ($\alpha^*$): Die Sprache $L_{reg}(\alpha^*)$ enthält alle möglichen Verkettungen von Wörtern aus $L_{reg}(\alpha)$, einschließlich des Leerworts $\varepsilon$. Mathematisch: $L_{reg}(\alpha^*) = L_{reg}(\alpha)^*$.

Nur Ausdrücke, die nach diesen Regeln gebildet werden können, sind reguläre Ausdrücke. Bei der Auswertung von regulären Ausdrücken gelten Vorrangregeln: zuerst der Kleene-Stern, dann die Konkatenation und zuletzt die Vereinigung.

### Beispiele

Bsp.: Es seien $A = \{0, 1, 2\}$ und $B = \{2, 3\}$. Dann ist:
*   $A \cup B = \{0, 1, 2, 3\}$
*   $A^* = \{\varepsilon, 0, 1, 2, 00, 11, 22, 01, 10, 12, 21, 02, 20, \dots\}$
*   $A^+ = \{0, 1, 2, 11, 22, 01, 10, 12, 21, 02, 20, \dots\}$

Bsp.: Sprachen $L_1 = \{aab, ab\}$ und $L_2 = \{aba, b\}$.
*   $L_1 L_2 = \{aababa, aabb, ababa, abb\}$
*   $L_1^* = \{\varepsilon, aab, ab, aabaab, aabab, abab, abaab, \dots\}$

Bsp.: Regulärer Ausdruck $r = (aa)^*(bb)^*b$
Die Sprache, die dieser Ausdruck beschreibt, ist:
$L = L_{reg}(r) = \{a^{2n} b^{2m+1} \mid n \ge 0, m \ge 0\}$

Bsp.: Finde einen regulären Ausdruck $r$ für das Alphabet $\Sigma = \{0, 1\}$, sodass die Sprache $L$ alle Wörter enthält, die **mindestens ein Paar aufeinanderfolgender Nullen** ($00$) haben.
$L = \{w \in \Sigma^* \mid w \text{ enthält wenigsten ein Paar aufeinanderfolgender Nullen}\}$
Der Ausdruck $r$ ist:
$r = (0+1)^*00(0+1)^*$
*Erklärung*: Der Ausdruck $(0+1)^*$ am Anfang und Ende erlaubt beliebige Kombinationen von $0$en und $1$en. In der Mitte muss aber zwingend die Kombination $00$ vorkommen.

Bsp.: Finde einen regulären Ausdruck $r$ für das Alphabet $\Sigma = \{0, 1\}$, sodass die Sprache $L$ alle Wörter enthält, die **kein Paar aufeinanderfolgender Nullen** ($00$) haben.
$L = \{w \in \Sigma^* \mid w \text{ enthält kein Paar aufeinanderfolgender Nullen}\}$
Mögliche Ausdrücke $r$ sind:
*   $r_1 = (1^*01^*)^*(0+\varepsilon)+1^*(0+\varepsilon)$
*   $r_2 = (1^*+01)^*(0+\varepsilon)$
*Erklärung*: Diese Ausdrücke stellen sicher, dass zwischen zwei $0$en immer mindestens eine $1$ steht, sodass nie $00$ auftritt. Der Term $(0+\varepsilon)$ am Ende fängt Fälle ab, in denen das Wort mit einer $0$ endet oder leer ist.

![[Pasted image 20251201163159.png]]

## 4.15 Grammatik Typen

1. Jede Grammatik ist automatisch vom Typ 0 oder __unbeschränkt__, d.h., die Produktionsregeln sind keiner Beschränkung unterworfen.

2. Eine Grammatik ist vom Typ 1 oder __kontextsensitiv__, wenn für alle Produktionsregeln folgende Bedingung gilt: Die Anzahl der Terminale und Nichtterminale auf der linken Seite einer Produktion ist nicht größer als die Anzahl der Terminale und Nichtterminale auf der rechten Seite. $S \rightarrow \epsilon$ ist zulässig, wenn S nie rechts steht.
   
   Beispiel: $S \rightarrow aSBC$, $CB \rightarrow BC$, $aB \rightarrow ab$
   Gegenbeispiel: $aS \rightarrow a$ (Verletzung: $|aS| > |a|$)

2. Eine Grammatik ist vom Typ 2 oder __kontextfrei__, wenn sie vom Typ 1 ist und zusätzlich gilt, dass auf der linken Seite einer Produktionsregel nur ein Nichtterminal auftritt.
   $X \rightarrow \epsilon, X \in \mathbb{N}$ ist zulässig
   
   Beispiel: $S \rightarrow aSb$, $S \rightarrow ab$, $S \rightarrow \epsilon$
   Gegenbeispiel: $aS \rightarrow ab$, $S \rightarrow aSb$

2. Eine Grammatik ist vom Typ 3 oder __regulär__, wenn sie vom Typ 2 ist und auf der rechten Seite einer Produktionsregel entweder ein einzelnes Terminalsymbol steht oder ein Terminalsymbol gefolgt von einer Variablen (bzw. eine Variable gefolgt von einem Terminalzeichen; rechtslinear bzw. linkslinear).
   
   Beispiel: $S \rightarrow aS$, $S \rightarrow aB$, $B \rightarrow b$
   Gegenbeispiel: $S \rightarrow aSb$ (Verletzung: $aSb$ hat Form Terminal-Nichtterminal-Terminal)


Aufgrund der Definition können wir nun die einzelnen Sprachen aus den vorigen Beispielen klassifizieren: $L(G_1)$ regulär, $L(G_2)$ kontextfrei, $L(G_3)$ monoton.

![[Pasted image 20251201164446.png]]
