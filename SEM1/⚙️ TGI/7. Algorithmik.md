## 7.1 Verschiedene Algorithmen

### 7.1.1 Quadratwurzel

Entstand aus Problemen der Flächenmessung bei den Babyloniern (ca. 1700 vor Christus)

Wurde von Heron von Alexandria (100 nach Christus) aufgegriffen
- Ziel ist es, die Quadratwurzel zu berechnen
- Hierbei werden schrittweise immer quadratähnlichere Rechtecke konstruiert, deren Flächeninhalt sich nicht ändert
- Eine Seite des Rechtecks wird als arithmetisches Mittel der beiden aktuellen Seiten gewählt, die andere Seite ergibt sich dann so, dass der Flächeninhalt gleich bleibt

Formeln zur Berechnung (Heron-Verfahren):
- $x_1 = \frac{x_0 + y_0}{2}$ und $y_1 = \frac{a}{x_1}$
- $x_{n+1} = \frac{x_n + y_n}{2}$ und $y_{n+1} = \frac{a}{x_{n+1}}$
- Eine vereinfachte Form ist: $x_{n+1} = \frac{x_n + a/x_n}{2}$

Bsp.: Berechnung der Quadratwurzel von $a=9$
1. Schritt: $a=9$, $x_0=9$, $y_0=1$
2. Schritt: $x_1 = \frac{9+1}{2} = 5$, $y_1 = \frac{9}{5}$
3. Schritt: $x_2 = \frac{5+9/5}{2} = \frac{34}{10} = 3.4$, $y_2 = \frac{9}{3.4} = 2.647$
4. Schritt: $x_3 = \frac{3.4+2.647}{2} = 3.02$, $y_3 = \frac{9}{3.02} = 2.98$

![[Pasted image 20251211101043.png]]

### 7.1.2 ggT

Problem des größten gemeinsamen Teilers (ggT), spielt eine wichtige Rolle in der Mathematik, Bsp.: Bruchrechnung

Euklid von Alexandria (ca. 365 bis 300 v. Chr.)
- beschrieb ein Verfahren: "Nimmt man abwechselnd immer das Kleinere vom Größeren weg, dann muss der Rest schließlich die vorhergehende Größe messen"
- Diese Methode ist in "Die Elemente, Zehntes Buch §3" festgehalten

Die mathematische Darstellung ist: $a = q \cdot b + r$ mit $0 \le r < b$

Bsp.: Berechnung des ggT von 18 und 4
- 18 und 4 | $18 - 4 = 14$
- 14 und 4 | $14 - 4 = 10$
- 10 und 4 | $10 - 4 = 6$
- 6 und 4 | $6 - 4 = 2$
- 4 und 2 | $4 - 2 = 2$
- Der ggT ist 2

### 7.1.3 Primzahlen

Siebverfahren zur Ermittlung von Primzahlen, wichtige Rolle in der Zahlentheorie

Eratosthenes von Kyrene (ca. 276 – 194 v. Chr.)
1. alle Zahlen des zu untersuchenden Bereichs aufschreiben (nur Bitfelder notwendig)
2. zur nächsten noch nicht gestrichenen Zahl vorrücken
3. von dieser Zahl ausgehend alle Vielfachen streichen
4. zu Schritt 2 gehen, wenn Zahl kleiner als $\sqrt{\text{Wurzel}}$ (siehe Bemerkung)
alle nicht gestrichenen Zahlen des Feldes sind die Primzahlen

Bemerkung: es müssen nur Vielfache einer Zahl gestrichen werden, höchstens bis zur Wurzel der größten zu ermittelnden Primzahl

Die Komplexität des Siebverfahrens ist $O(n \log \log n)$

![[Pasted image 20251211101559.png]]

### 7.1.4 Kreiszahl

Approximation von $\pi$, wichtige Rolle bei Flächen- und Körperberechnungen

Archimedes von Syrakus (ca. 287 – 212 v. Chr.)
1. die Annäherung des Kreises erfolgt durch einbeschriebene und umbeschriebene regelmäßige Vielecke
2. die Umfänge der Vielecke werden berechnet unter Verwendung des Satzes von Pythagoras
3. die Umfänge der einbeschriebenen und umbeschriebenen Vielecke nähern sich sehr stark an, sodass das 96-Eck schon einen auf drei Dezimalstellen genauen Wert für $\pi$ liefert

![[Pasted image 20251211101705.png]]

## 7.2 Problemlösungsstrategien

Für die Lösung von Problemen muss zuerst die Art des Problems bestimmt werden

Es gibt verschiedene Problemarten:
* nichtalgorithmische Probleme (Bsp.: Blei in Gold verwandeln)
* theoretisch nicht lösbare algorithmische Probleme (Bsp.: Halteproblem, Entscheidungsproblem)
* praktisch nicht lösbare bzw. sehr schwer lösbare Probleme (Bsp.: Problem des Handelsreisenden, Stundenplan-Problem)
* praktisch lösbare Probleme (Bsp.: Suchen, Sortieren)

Die Einteilung kann nach verschiedenen Gesichtspunkten erfolgen. In diesem Abschnitt werden einige heuristische Strategien vorgestellt


__Heuristik__

* der Begriff Heuristik kommt aus dem Griechischen
* das Verb „heuriskein“ bedeutet finden oder entdecken
* der berühmteste Gelehrte der Antike, Archimedes von Syrakus, soll nach der Entdeckung des Auftriebs während eines Bades „heureka“ rufend auf die Straße gelaufen sein
* Heuristik ist die Lehre des Problemlösens

### 7.2.1 Elementare Strategien

* elementare Methoden (direkt, naiv, straightforward) sind oft sehr allgemein und für viele Fälle anwendbar
* sie sind sehr effizient, wenn exakte Formeln bekannt sind
* raffiniertere Herangehensweisen sind oft nur bei bestimmten Fällen anwendbar
* die Methode der rohen Gewalt („brute force method“) probiert alle Möglichkeiten durch
* diese Methode ist meist sehr aufwändig (hohe Komplexität), Bsp.: durchprobieren aller Züge bis zu einer bestimmten Tiefe beim Schachspiel
* die gierige Strategie („greedy strategy“) erledigt immer das nächste, für das Problem beste, Teilproblem
* Bsp.: beim TSP (Problem des Handelsreisenden) wird immer zur nächstgelegenen Stadt gereist

### 7.2.2 Computerorientierte Strategien

* Modularität: das Problem wird in Teilprobleme zerlegt, die einfacher zu lösen sind (Baukastenprinzip)
* die Lösung der einzelnen Teilprobleme wird zur Gesamtlösung zusammengesetzt
* Rekursion ist ein fundamentales heuristisches Prinzip
* viele Probleme sind „von Hause aus“ rekursiv
* Rekursion zeigt sich in Selbstähnlichkeit (Bsp.: Ornamente, Fraktale)
* es ist eng verbunden mit dem Prinzip der vollständigen Induktion
* dabei werden kleinere Kopien desselben Problems bis zur kleinsten Stufe bearbeitet
* Versuch und Irrtum („trial and error“) bedeutet nacheinander verschiedene Möglichkeiten auszuprobieren

### 7.2.3 Rekursion

Problemstellung: Wie viele Kaninchenpaare gibt es nach einem Jahr, wenn anfangs ein junges Paar geboren wird, jedes Paar jeden Monat ein neues Paar zur Welt bringt und alle Jungen sich jeweils nach einem Monat fortpflanzen

Zahlenreihe: 1 1 2 3 5 8 13 21 34 55 89 144 ...

Mathematische Beschreibung: $F_0 = 0$, $F_1 = 1$, $F_{n+2} = F_{n+1} + F_n$ für $n \ge 0$

Die einfache Übernahme der rekursiven Formel für die Fibonacci-Zahlen kann den Computer für Stunden oder Tage auslasten

![[Pasted image 20251211103544.png]]

### 7.2.4 Weitere Problemlösungsstrategien

Prinzip „Teile und Herrsche“ („divide and conquer“)
- Das Problem wird in etwa gleich große Teilprobleme zerlegt
- Die Gesamtlösung wird aus den Teillösungen zusammengesetzt
- Algorithmen werden meist rekursiv formuliert
- Bsp.: Quicksort

Systematisches Durchlaufen von Baumstrukturen
- Breitensuche („breadth first“)
- Tiefensuche („depth first“)
- Backtracking ist eine Modifikation der Tiefensuche: es wird nur so weit in die Tiefe gegangen, wie zum Erkennen einer Lösung nötig ist

Gezielte mathematische Analyse
- liefert oft sehr effiziente Lösungen
- Bsp.: Lösung von quadratischen Gleichungen
- NIM-Spiel

Geometrische Algorithmen
Graphen-Algorithmen

Probabilistische Verfahren
- Verzicht auf hundertprozentige Sicherheit (Pseudo-Primzahlen)
- Bsp.: Public Key Kryptografie (RSA-Verfahren)

Simulationsverfahren

Evolutionäre Algorithmen (EA), Genetische Algorithmen (GA)
- DNA-Algorithmen
- Zelluläre Automaten
- Neuronale Netze

Parallele Algorithmen
Dynamische Programmierung

### 7.2.5 Gierige Strategie "greedy strategy"

__Prinzip__: In jedem Teilschritt so viel wie möglich erreichen

Bei manchen Problemen kann dies eine optimale Strategie sein
Bsp.: Herausgabe von Wechselgeld
Ziel: möglichst wenige Scheine und Münzen herausgeben
- Preis: 37,34 € => Herausgabe 12,66 €
- Bsp.: 10 €-Schein + 2 €-Münze + 0,50 €-Münze + 0,10 €-Münze + 0,05 €-Münze + 0,01 €-Münze

Bei anderen Problemen kann die gierige Strategie zu falschen Lösungen führen
Bsp.: Schachspiel

## 7.3 Elementare Sortierverfahren

### 7.3.1 Select-Sort

**Aktionen je Schritt**
- das i-te Element wird zunächst als kleinstes Element des Restfeldes angenommen
- vom i-ten Element beginnend wird das Feld nach kleineren Elementen durchsucht und der Index wird festgehalten
- pro Schritt wird das gefundene kleinste Element mit dem i-ten Element vertauscht (wenn es ungleich dem i-ten Element ist)

**Ergebnisse je Schritt**
- je Schritt ist höchstens eine Vertauschung nötig
- die kleinste Zahl wurde an die erste Stelle des untersuchten Restfeldes getauscht
- das zu untersuchende Feld wird je Schritt um ein Element kleiner

**Ende des Algorithmus**
- bei n Elementen nach $n-1$ Schritten

```c
int selectSort(int feld[], int anz)
{
  int i, j, hilf, minIndex;

  for (i= 0; i < anz-1; i++)
  {
    minIndex= i;

    for (j= i+1; j < anz; j++)
      if (feld[j] < feld[minIndex])
        minIndex= j;

    if (minIndex != i)
    {
      hilf= feld[i];
      feld[i]= feld[minIndex];
      feld[minIndex]= hilf;
    }
  }
  return 0;
}
```

### 7.3.2 Insert-Sort

**Aktionen je Schritt**
- wie beim Einsortieren der Karten werden die Elemente nacheinander betrachtet und an den richtigen Platz der bereits betrachteten Elemente eingefügt
- die größeren Elemente des bereits vorsortierten (linken) Feldes werden um eine Stelle nach rechts verschoben
- das aktuell betrachtete Element wird an die freigewordene Stelle eingefügt

**Ergebnisse je Schritt**
- die links stehenden Elemente sind sortiert, aber es kommen weitere Elemente hinzu
- der Test $j > 0$ in der inneren Schleife ist ineffizient
- das zu untersuchende Restfeld wird je Schritt um ein Element kleiner

**Ende des Algorithmus**
- bei n Elementen nach $n-1$ Schritten


__Beispiel__

- Buben ganz links in der Reihenfolge: Kreuz, Pik, Herz, Karo
- rechts von den Buben die Reihenfolge der Farben: Kreuz, Herz, Pik, Karo
- die Karten der Farben in der Reihenfolge: As, Zehn, König, Dame, Neun, Acht, Sieben

![[Pasted image 20251211104325.png]]

```c
int insertSort(int feld[], int anz)
{
  int i, j, hilf;

  for (i= 1; i < anz; i++) // anz-1 Schritte
  {
    hilf= feld[i];

    for (j= i; feld[j-1] > hilf && j > 0; j--)
      feld[j]= feld[j-1];

    feld[j]= hilf;
  }
  return 0;
}
```

### 7.3.3 Bubble-Sort

**Aktionen je Schritt**
- von unten beginnend werden die zwei benachbarten Zahlen verglichen und gegebenenfalls vertauscht
- dadurch steigen die kleineren Zahlen wie Blasen nach oben und größere Zahlen je Schritt um eine Stelle nach unten

**Ergebnisse je Schritt**
- die kleinste Zahl ist garantiert an die erste Stelle des untersuchten Restfeldes gestiegen
- das zu untersuchende Feld wird je Schritt um ein Element kleiner

**Ende des Algorithmus**
- bei n Elementen nach höchstens $n-1$ Schritten
- wenn in einem Schritt kein Tausch mehr durchzuführen ist


__Beispiel__

![[Pasted image 20251211104619.png]]

```c
int bubbleSort(int feld[], int anz)
{
  int i, j, hilf;
  int sortiert= 1;

  for (i= 0; i < anz-1; i++)
  {
    sortiert= 1;

    for (j= anz-1; j > i; j--)
      if (feld[j] < feld[j-1])
      {
        hilf= feld[j-1];
        feld[j-1]= feld[j];
        feld[j]= hilf;
        sortiert= 0;
      }

    if (sortiert) break;
  }
  return 0;
}
```

### 7.3.4 Quicksort

Prinzip „Teile und Herrsche“

**Aktionen je Schritt**
- die zu sortierende Folge wird in zwei zu sortierende Folgen zerlegt
- zuerst wird ein Element gewählt, das in die endgültige Position gebracht werden soll (möglichst in die Mitte der Folge)
- dazu laufen zwei Zeiger von links und rechts aufeinander zu und die Elemente werden mit dem Vergleichs-Element verglichen
- wenn die Zeiger stoppen, werden die Elemente, die offensichtlich an falscher Stelle stehen, vertauscht
- die entstandenen vorsortierten Teilfolgen werden rekursiv erneut betrachtet

**Ende des Algorithmus**
- die zu untersuchende Teilfolge besteht nur noch aus einem Element

![[Pasted image 20251211104852.png]]

```c
int quickSort(int feld[], int li, int re)
{
  int i, j, vergl, hilf;

  if (re > li)
  {
    vergl= feld[re]; i= li-1; j= re;
    while (1)
    {
      while(feld[--j] > vergl) ; // Suche von rechts
      while(feld[++i] < vergl) ; // Suche von links
      if (i >= j) break;          // Zeiger getroffen
      hilf= feld[i]; feld[i]= feld[j]; // Tausch,
      feld[j]= hilf;             // wenn noetig
    }
    hilf= feld[re]; feld[re]= feld[i]; // Vergleichs-
    feld[i]= hilf;                 // Element in Mitte tauschen

    quickSort(feld, li, i-1);      // linker Teil
    quickSort(feld, i+1, re);      // rechter Teil
  }
  return 0;
}
```

### 7.4.5 Komplexität

**Select-Sort (Auswahl-Sortieren)**
- die äußere Schleife wird $n-1$ mal durchlaufen
- die innere Schleife wird im Durchschnitt $(n-1)/2$ mal durchlaufen
- $\Rightarrow O((n-1)*((n-1)/2)) = O((n-1)^2/2) = O(n^2)$

**Insert-Sort (Einfüge-Sortieren)**
- die äußere Schleife wird $n-1$ mal durchlaufen
- die innere Schleife wird im Durchschnitt $1/2 * 1/2 * (n-1)$ mal durchlaufen
- im Mittel wird erwartet, dass das neue Element in die Mitte des sortierten Bereichs gehört
- $\Rightarrow O((n-1)*(1/2)*((n-1)/2)) = O((n-1)^2/4) = O(n^2)$

**Bubble-Sort**
- die äußere Schleife wird $n-1$ mal durchlaufen
- die innere Schleife wird im Durchschnitt $(n-1)/2$ mal durchlaufen
- $\Rightarrow O((n-1)*((n-1)/2)) = O((n-1)^2/2) = O(n^2)$

**Quicksort**
- die Rekursionstiefe hängt vom Vergleichselement ab und ist im besten Fall $ld(n)$ und im mittleren Fall etwa $1,4 * ld(n)$
- $\Rightarrow O(n \ ld \ (n))$

## 7.4 Dijkstra-Algorithmus

Problem: kürzester Wege von Startpunkt zu allen Zielpunkte in einem gegebenen Netz

> Der Algorithmus von Dijkstra berechnet die kürzesten Wege von einem Startpunkt zu allen erreichbaren Zielpunkten.
> (Entweder direkt oder über andere Punkte hinweg)

Der Dijkstra-Algorithmus funktioniert nur bei positiv gewichteten Graphen
arbeitet analog zur trickreichen Lösung mittels Bindfäden

![[Pasted image 20260105121733.png]]
(Es wird das weggestrichen für was man bereits eine bessere Lösung hat, immer von A aus gesehen)

![[2021_01_28_Dijkstra-Algorithmik.mp4]]

## 7.5 Backtracking-Algorithmen

- Sehr viele praktische Probleme lassen sich auf diese Weise lösen
- Beim Backtracking wird der komplette Lösungsraum systematisch abgearbeitet
- Der Algorithmus terminiert, wenn der Lösungsraum endlich ist
- Es entsteht in Abhängigkeit der Möglichkeiten oft exponentieller Aufwand

>Wenn ein Zweig in eine Sackgasse gerät, wird zur nächsten noch nicht bearbeiteten Abzweigung zurück gekehrt (Backtracking)

1. Alle Lösungen finden
2. Abbruch bei der ersten gefundenen Lösung
3. Es werden bewertete Lösungen berechnet und es wird die beste ausgewählt
4. „Branch-and-Bound“ verfolgt nur Zweige, die eine Lösung prinzipiell zulassen. Es wird versucht, Wege in Sackgassen zu vermeiden
5. Vorgabe einer maximalen Rekursionstiefe